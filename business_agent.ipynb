{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8d14bb4",
      "metadata": {
        "id": "e8d14bb4"
      },
      "source": [
        "# üêù TutorBee - Smart Business Agent\n",
        "\n",
        "This notebook implements an AI-powered chatbot for TutorBee, an interactive tutoring service.\n",
        "\n",
        "## Features:\n",
        "- Answer questions about TutorBee's services\n",
        "- Collect customer leads (name, email, notes)\n",
        "- Record unanswered questions and feedback\n",
        "- Deploy via Gradio interface\n",
        "\n",
        "### Deployed HuggingFace link:\n",
        "https://huggingface.co/spaces/safaasalman/tutorbee-assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8d419c5",
      "metadata": {
        "id": "f8d419c5"
      },
      "source": [
        "## 1. Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e18a53aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e18a53aa",
        "outputId": "2db3a0fd-32f5-42d5-c249-cc34612db0f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.119.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai gradio python-dotenv PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec1398a0",
      "metadata": {
        "id": "ec1398a0"
      },
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "296cb88f",
      "metadata": {
        "id": "296cb88f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any\n",
        "import PyPDF2\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "994165c2",
      "metadata": {
        "id": "994165c2"
      },
      "source": [
        "## 3. Load Business Information\n",
        "\n",
        "**Note:** Upload your `about_business.pdf` and `business_summary.txt` files from the `me/` folder to Colab before running this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "70860c84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70860c84",
        "outputId": "123c410b-976d-4c96-9e7c-c33eb76e4be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded business_summary.txt\n",
            "‚úÖ Loaded about_business.pdf\n",
            "\n",
            "üìö Business context loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "def load_business_context():\n",
        "    \"\"\"\n",
        "    Load business information from uploaded files.\n",
        "    \"\"\"\n",
        "    context = \"\"\n",
        "\n",
        "    # Load text summary\n",
        "    try:\n",
        "        with open('/content/me/business_summary.txt', 'r', encoding='utf-8') as f:\n",
        "            context += f.read() + \"\\n\\n\"\n",
        "        print(\"‚úÖ Loaded business_summary.txt\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ö†Ô∏è business_summary.txt not found. Please upload it.\")\n",
        "\n",
        "    # Load PDF content\n",
        "    try:\n",
        "        with open('/content/me/about_business.pdf', 'rb') as f:\n",
        "            pdf_reader = PyPDF2.PdfReader(f)\n",
        "            pdf_text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                pdf_text += page.extract_text()\n",
        "            context += \"Additional Business Information:\\n\" + pdf_text\n",
        "        print(\"‚úÖ Loaded about_business.pdf\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ö†Ô∏è about_business.pdf not found. Please upload it.\")\n",
        "\n",
        "    return context\n",
        "\n",
        "# Load business context\n",
        "BUSINESS_CONTEXT = load_business_context()\n",
        "print(\"\\nüìö Business context loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e177558",
      "metadata": {
        "id": "5e177558"
      },
      "source": [
        "## 4. Define Tool Functions\n",
        "\n",
        "These functions will be called by the AI agent to collect leads and feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ee6c44e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6c44e1",
        "outputId": "64ffbb02-99a9-4c16-8e47-d0b50743542b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tool functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Storage for leads and feedback\n",
        "leads_database = []\n",
        "feedback_database = []\n",
        "\n",
        "def record_customer_interest(email: str, name: str, message: str) -> str:\n",
        "    \"\"\"\n",
        "    Record customer lead information.\n",
        "\n",
        "    Args:\n",
        "        email: Customer's email address\n",
        "        name: Customer's name\n",
        "        message: Additional notes or interests\n",
        "\n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    lead_entry = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"name\": name,\n",
        "        \"email\": email,\n",
        "        \"message\": message\n",
        "    }\n",
        "\n",
        "    leads_database.append(lead_entry)\n",
        "\n",
        "    # Log to console\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìù NEW LEAD RECORDED\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Timestamp: {timestamp}\")\n",
        "    print(f\"Name: {name}\")\n",
        "    print(f\"Email: {email}\")\n",
        "    print(f\"Message: {message}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Also save to file\n",
        "    with open('leads_log.json', 'w') as f:\n",
        "        json.dump(leads_database, f, indent=2)\n",
        "\n",
        "    return f\"Thank you, {name}! Your interest has been recorded. We'll contact you at {email} soon.\"\n",
        "\n",
        "\n",
        "def record_feedback(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Record unanswered questions or customer feedback.\n",
        "\n",
        "    Args:\n",
        "        question: The question or feedback that couldn't be answered\n",
        "\n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    feedback_entry = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"question\": question\n",
        "    }\n",
        "\n",
        "    feedback_database.append(feedback_entry)\n",
        "\n",
        "    # Log to console\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üí¨ FEEDBACK/UNANSWERED QUESTION RECORDED\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Timestamp: {timestamp}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Also save to file\n",
        "    with open('feedback_log.json', 'w') as f:\n",
        "        json.dump(feedback_database, f, indent=2)\n",
        "\n",
        "    return \"Thank you for your question. I've recorded it and our team will review it to improve our service.\"\n",
        "\n",
        "\n",
        "print(\"‚úÖ Tool functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30aa14b8",
      "metadata": {
        "id": "30aa14b8"
      },
      "source": [
        "## 5. Define Tool Schemas for OpenAI Function Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ebcf61bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebcf61bf",
        "outputId": "4d8aa34a-d151-49fd-b66c-4970d3c2fb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tool schemas defined successfully!\n"
          ]
        }
      ],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_customer_interest\",\n",
        "            \"description\": \"Record a customer's contact information and interest in TutorBee services. Use this when a customer wants to sign up, get more information, or schedule a session.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"email\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The customer's email address\"\n",
        "                    },\n",
        "                    \"name\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The customer's full name\"\n",
        "                    },\n",
        "                    \"message\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Additional notes about what the customer is interested in or their specific needs\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"email\", \"name\", \"message\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_feedback\",\n",
        "            \"description\": \"Record questions that you cannot answer or customer feedback for future improvement. Use this when you don't have enough information to answer a customer's question.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"question\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unanswered question or feedback from the customer\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"question\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Tool schemas defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f3248d",
      "metadata": {
        "id": "70f3248d"
      },
      "source": [
        "## 6. Set Up OpenAI API\n",
        "\n",
        "**Important:** Add your OpenAI API key to Colab Secrets:\n",
        "1. Click the key icon (üîë) in the left sidebar\n",
        "2. Add a secret named `OPENAI_API_KEY`\n",
        "3. Paste your API key as the value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3c9af7a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c9af7a4",
        "outputId": "04efb004-916d-4566-d91a-36adeed59365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI client initialized successfully!\n",
            "üìå Using Model: gpt-4o-mini\n"
          ]
        }
      ],
      "source": [
        "# Get API key from Colab secrets\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    print(\"‚úÖ OpenAI client initialized successfully!\")\n",
        "    print(\"üìå Using Model: gpt-4o-mini\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Please add your OPENAI_API_KEY to Colab Secrets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8a5693",
      "metadata": {
        "id": "5e8a5693"
      },
      "source": [
        "## 7. Create the TutorBee Agent Class\n",
        "\n",
        "### System Prompt Design Principles:\n",
        "\n",
        "The system prompt is carefully crafted to:\n",
        "\n",
        "‚úÖ **Stay In Character**: Agent acts as \"Alex from TutorBee\", never breaking character\n",
        "\n",
        "‚úÖ **Use Business Context**: All answers come from the loaded PDF and TXT files - no hallucination\n",
        "\n",
        "‚úÖ **Log Unknown Questions**: Automatically calls `record_feedback()` for anything not in the documentation\n",
        "\n",
        "‚úÖ **Encourage Lead Collection**: Proactively asks for contact info when customers show interest\n",
        "\n",
        "‚úÖ **Professional & Friendly**: Balances warmth with professionalism to build trust"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a904ec5c",
      "metadata": {
        "id": "a904ec5c"
      },
      "source": [
        "### üîÑ Agent Interaction Flow\n",
        "\n",
        "The agent follows this interaction pattern:\n",
        "\n",
        "```\n",
        "1. User sends message\n",
        "   ‚Üì\n",
        "2. Add message to chat history\n",
        "   ‚Üì\n",
        "3. Send to OpenAI API with:\n",
        "   - Chat history (context)\n",
        "   - System prompt (behavior)\n",
        "   - Available tools (functions)\n",
        "   ‚Üì\n",
        "4. Model decides:\n",
        "   - Answer directly? ‚Üí Return text\n",
        "   - Need to call tool? ‚Üí Execute function\n",
        "   ‚Üì\n",
        "5. If tool called:\n",
        "   - Execute Python function\n",
        "   - Add result to history\n",
        "   - Get final response from model\n",
        "   ‚Üì\n",
        "6. Return response to user\n",
        "```\n",
        "\n",
        "This implements the standard **function calling** pattern used by OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ec57cd7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec57cd7a",
        "outputId": "7b95a985-b6d0-4983-bacd-d595ec42a90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TutorBeeAgent class created successfully!\n",
            "üìå Using OpenAI API with gpt-4o-mini model\n"
          ]
        }
      ],
      "source": [
        "class TutorBeeAgent:\n",
        "    \"\"\"\n",
        "    Smart agent for TutorBee business interactions using OpenAI.\n",
        "\n",
        "    This class implements the core agent interaction pattern:\n",
        "    1. Receives user input\n",
        "    2. Maintains chat history for context\n",
        "    3. Sends request to AI model with available tools\n",
        "    4. Handles tool calls if model requests them\n",
        "    5. Returns final response to user\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, client, business_context: str):\n",
        "        \"\"\"\n",
        "        Initialize the TutorBee agent.\n",
        "\n",
        "        Args:\n",
        "            client: OpenAI client instance\n",
        "            business_context: Business information loaded from PDF and TXT files\n",
        "        \"\"\"\n",
        "        self.client = client\n",
        "        self.business_context = business_context\n",
        "        self.conversation_history = []\n",
        "\n",
        "        # System prompt - defines agent behavior\n",
        "        self.system_prompt = f\"\"\"You are Alex, a friendly and professional customer service representative for TutorBee, an AI-powered interactive tutoring service.\n",
        "\n",
        "CRITICAL: You must ALWAYS stay in character as a TutorBee representative. Never break character or reveal that you are an AI language model.\n",
        "\n",
        "Your role and responsibilities:\n",
        "1. Answer questions about TutorBee using ONLY the information provided in the business documentation below\n",
        "2. Help potential customers understand how TutorBee can transform their learning journey\n",
        "3. Proactively encourage interested visitors to leave their contact information\n",
        "4. Use the record_feedback tool for ANY question you cannot answer from the provided information\n",
        "\n",
        "Business Information (THIS IS YOUR ONLY SOURCE OF TRUTH):\n",
        "{self.business_context}\n",
        "\n",
        "Behavioral Guidelines:\n",
        "- Stay in character as \"Alex from TutorBee\" - you work here and are passionate about education\n",
        "- Be warm, conversational, enthusiastic, and genuinely helpful\n",
        "- Use the business information above to answer ALL questions - do not make up information\n",
        "- If asked about pricing, features, policies, or anything NOT in the documentation, use record_feedback tool immediately\n",
        "- Proactively ask for contact details when customers show ANY interest (questions about features, pricing, scheduling, etc.)\n",
        "\n",
        "Lead Collection Strategy:\n",
        "- When a customer asks multiple questions or shows sustained interest, say something like: \"I'd love to help you get started! May I have your name and email so we can send you personalized information?\"\n",
        "- When someone asks about signing up, pricing, or scheduling: \"Great! Let me collect your details so our team can reach out. What's your name and email?\"\n",
        "- Make it natural and helpful, not pushy\n",
        "\n",
        "Unknown Question Protocol:\n",
        "- If you don't know the answer from the business information provided, immediately say: \"That's a great question! I don't have that specific information right now, but let me record this for our team to follow up with you.\"\n",
        "- Then use the record_feedback tool to log it\n",
        "- NEVER make up information not in the business documentation\n",
        "\n",
        "Response Style:\n",
        "- Keep responses concise (2-4 sentences typically)\n",
        "- Use emojis sparingly to add warmth (üêù, üìö, ‚ú®, üéØ)\n",
        "- Be professional yet personable\n",
        "- Show genuine excitement about helping students succeed\n",
        "\"\"\"\n",
        "\n",
        "        # Initialize chat history with system prompt\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": self.system_prompt\n",
        "        })\n",
        "\n",
        "    def chat(self, user_message: str) -> str:\n",
        "        \"\"\"\n",
        "        Process user message and return agent response.\n",
        "\n",
        "        This method implements the complete interaction flow:\n",
        "        1. Add user message to chat history\n",
        "        2. Send to AI model with tools available\n",
        "        3. Check if model wants to call a tool\n",
        "        4. If yes: execute tool and get final response\n",
        "        5. If no: return generated text directly\n",
        "\n",
        "        Args:\n",
        "            user_message: The user's input text\n",
        "\n",
        "        Returns:\n",
        "            The agent's response text\n",
        "        \"\"\"\n",
        "        # Step 1: Add user message to history\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message\n",
        "        })\n",
        "\n",
        "        # Step 2: Call OpenAI API with function calling capability\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=self.conversation_history,\n",
        "            tools=tools,  # Available functions\n",
        "            tool_choice=\"auto\"  # Let model decide when to use tools\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message\n",
        "\n",
        "        # Step 3: Check if the model wants to call a function\n",
        "        if assistant_message.tool_calls:\n",
        "            # Model requested tool execution\n",
        "            self.conversation_history.append(assistant_message)\n",
        "\n",
        "            # Step 4: Process each tool call\n",
        "            for tool_call in assistant_message.tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                # Execute the appropriate function\n",
        "                if function_name == \"record_customer_interest\":\n",
        "                    function_response = record_customer_interest(\n",
        "                        email=function_args.get(\"email\"),\n",
        "                        name=function_args.get(\"name\"),\n",
        "                        message=function_args.get(\"message\")\n",
        "                    )\n",
        "                elif function_name == \"record_feedback\":\n",
        "                    function_response = record_feedback(\n",
        "                        question=function_args.get(\"question\")\n",
        "                    )\n",
        "                else:\n",
        "                    function_response = \"Function not found.\"\n",
        "\n",
        "                # Add function response to conversation history\n",
        "                self.conversation_history.append({\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response\n",
        "                })\n",
        "\n",
        "            # Step 5: Get final response after function execution\n",
        "            second_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=self.conversation_history\n",
        "            )\n",
        "\n",
        "            final_message = second_response.choices[0].message.content\n",
        "            self.conversation_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": final_message\n",
        "            })\n",
        "\n",
        "            return final_message\n",
        "        else:\n",
        "            # No function call needed - return direct response\n",
        "            response_text = assistant_message.content\n",
        "            self.conversation_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": response_text\n",
        "            })\n",
        "            return response_text\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset conversation history to start fresh.\n",
        "        Useful for testing or starting a new conversation.\n",
        "        \"\"\"\n",
        "        self.conversation_history = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": self.system_prompt\n",
        "        }]\n",
        "\n",
        "print(\"‚úÖ TutorBeeAgent class created successfully!\")\n",
        "print(\"üìå Using OpenAI API with gpt-4o-mini model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf0c0252",
      "metadata": {
        "id": "cf0c0252"
      },
      "source": [
        "## 8. Create Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ce00b8d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce00b8d6",
        "outputId": "b28e5e5e-fba1-49e4-d0f3-d52848398192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ TutorBee agent initialized and ready!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gradio interface created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize the agent\n",
        "agent = TutorBeeAgent(client, BUSINESS_CONTEXT)\n",
        "print(\"ü§ñ TutorBee agent initialized and ready!\")\n",
        "\n",
        "def gradio_chat(message, history):\n",
        "    \"\"\"\n",
        "    Wrapper function for Gradio chat interface.\n",
        "    \"\"\"\n",
        "    response = agent.chat(message)\n",
        "    return response\n",
        "\n",
        "def view_leads():\n",
        "    \"\"\"\n",
        "    Display collected leads.\n",
        "    \"\"\"\n",
        "    if not leads_database:\n",
        "        return \"No leads collected yet.\"\n",
        "\n",
        "    output = \"## üìù Collected Leads\\n\\n\"\n",
        "    for i, lead in enumerate(leads_database, 1):\n",
        "        output += f\"**Lead #{i}**\\n\"\n",
        "        output += f\"- **Time:** {lead['timestamp']}\\n\"\n",
        "        output += f\"- **Name:** {lead['name']}\\n\"\n",
        "        output += f\"- **Email:** {lead['email']}\\n\"\n",
        "        output += f\"- **Message:** {lead['message']}\\n\\n\"\n",
        "    return output\n",
        "\n",
        "def view_feedback():\n",
        "    \"\"\"\n",
        "    Display collected feedback.\n",
        "    \"\"\"\n",
        "    if not feedback_database:\n",
        "        return \"No feedback recorded yet.\"\n",
        "\n",
        "    output = \"## üí¨ Recorded Feedback\\n\\n\"\n",
        "    for i, feedback in enumerate(feedback_database, 1):\n",
        "        output += f\"**Feedback #{i}**\\n\"\n",
        "        output += f\"- **Time:** {feedback['timestamp']}\\n\"\n",
        "        output += f\"- **Question:** {feedback['question']}\\n\\n\"\n",
        "    return output\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"TutorBee Assistant\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üêù Welcome to TutorBee!\n",
        "        ### Your AI-Powered Interactive Tutoring Service\n",
        "\n",
        "        Ask me anything about our services, pricing, team, or how we can help you succeed!\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"üí¨ Chat\"):\n",
        "        chatbot = gr.ChatInterface(\n",
        "            fn=gradio_chat,\n",
        "            examples=[\n",
        "                \"What services does TutorBee offer?\",\n",
        "                \"Tell me about your team\",\n",
        "                \"How does the AI tutoring assistant work?\",\n",
        "                \"I'm interested in signing up for math tutoring\",\n",
        "                \"What makes TutorBee different from other tutoring platforms?\"\n",
        "            ],\n",
        "            title=\"Chat with TutorBee Assistant\"\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üìä Analytics\"):\n",
        "        gr.Markdown(\"## View Collected Data\")\n",
        "\n",
        "        with gr.Row():\n",
        "            leads_btn = gr.Button(\"View Leads\", variant=\"primary\")\n",
        "            feedback_btn = gr.Button(\"View Feedback\", variant=\"secondary\")\n",
        "\n",
        "        output_display = gr.Markdown()\n",
        "\n",
        "        leads_btn.click(fn=view_leads, outputs=output_display)\n",
        "        feedback_btn.click(fn=view_feedback, outputs=output_display)\n",
        "\n",
        "print(\"‚úÖ Gradio interface created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d7a22b",
      "metadata": {
        "id": "56d7a22b"
      },
      "source": [
        "## 9. Test the System Prompt\n",
        "\n",
        "Test the agent's behavior before launching Gradio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "10fb7be1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10fb7be1",
        "outputId": "4f6f518c-fc93-446a-b5f2-a979588e008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ TEST 1: Asking about services\n",
            "\n",
            "Agent: TutorBee offers a range of interactive tutoring services, including:\n",
            "\n",
            "1. **AI Tutoring Assistant** - Explains difficult topics in real time and adapts to each student‚Äôs learning pace.\n",
            "2. **Smart Scheduling** - Automatically books tutoring sessions based on both tutor and student availability.\n",
            "3. **Performance Tracking** - Summarizes lessons and provides progress insights after each session.\n",
            "4. **Feedback Collection** - Allows students and tutors to leave feedback easily to continuously improve teaching quality.\n",
            "5. **Multi-Subject Support** - Covers key subjects like Math, Science, Languages, and Programming.\n",
            "\n",
            "If you're interested in how any specific service works, I'd love to provide more information! May I have your name and email to send personalized details?\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Ask about services (should answer from business context)\n",
        "print(\"üß™ TEST 1: Asking about services\\n\")\n",
        "response = agent.chat(\"What services does TutorBee offer?\")\n",
        "print(f\"Agent: {response}\\n\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "31bfc216",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31bfc216",
        "outputId": "4b11ab7b-532f-4ba2-fcf6-f9776c29b85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ TEST 2: Asking unknown question\n",
            "\n",
            "\n",
            "==================================================\n",
            "üí¨ FEEDBACK/UNANSWERED QUESTION RECORDED\n",
            "==================================================\n",
            "Timestamp: 2025-10-19 16:57:50\n",
            "Question: What's TutorBee's refund policy?\n",
            "==================================================\n",
            "\n",
            "Agent: I've recorded your question about the refund policy, and our team will review it to provide better information. If you have any other questions or if you're interested in our services, feel free to ask! Also, may I have your name and email to send you updates?\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Ask unknown question (should trigger record_feedback)\n",
        "print(\"\\nüß™ TEST 2: Asking unknown question\\n\")\n",
        "response = agent.chat(\"What's your refund policy?\")\n",
        "print(f\"Agent: {response}\\n\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "12596d89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12596d89",
        "outputId": "d1955f2a-b491-4f15-84fb-c2439e786306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ TEST 3: Expressing interest\n",
            "\n",
            "\n",
            "==================================================\n",
            "üìù NEW LEAD RECORDED\n",
            "==================================================\n",
            "Timestamp: 2025-10-19 16:57:53\n",
            "Name: Sarah Johnson\n",
            "Email: sarah.j@email.com\n",
            "Message: Interested in math tutoring for daughter.\n",
            "==================================================\n",
            "\n",
            "Agent: Thank you, Sarah Johnson! I've noted your interest in math tutoring for your daughter, and our team will reach out to you soon at your email, sarah.j@email.com. If you have any more questions or need further assistance in the meantime, feel free to ask! üìö‚ú®\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test 3: Express interest (should trigger lead collection)\n",
        "print(\"\\nüß™ TEST 3: Expressing interest\\n\")\n",
        "response = agent.chat(\"I'm interested in math tutoring for my daughter. My name is Sarah Johnson and my email is sarah.j@email.com\")\n",
        "print(f\"Agent: {response}\\n\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a9dd810c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9dd810c",
        "outputId": "9f580365-b28d-475b-89b4-dbaa2c0cdb8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Agent reset - ready for Gradio deployment!\n"
          ]
        }
      ],
      "source": [
        "# Reset agent for clean Gradio session\n",
        "agent.reset()\n",
        "print(\"\\n‚úÖ Agent reset - ready for Gradio deployment!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14caee8d",
      "metadata": {
        "id": "14caee8d"
      },
      "source": [
        "## 9. Launch the Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89413e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "b89413e5",
        "outputId": "df377ac9-9133-459a-d09a-a40c7064afef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://464ae4737ea32f888f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://464ae4737ea32f888f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Launch the Gradio app\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "726b2f0c",
      "metadata": {
        "id": "726b2f0c"
      },
      "source": [
        "## 10. Testing & Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a2615b59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2615b59",
        "outputId": "a18ea7e6-b2b0-410f-9825-51726c517545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù LEADS DATABASE:\n",
            "[\n",
            "  {\n",
            "    \"timestamp\": \"2025-10-19 16:57:53\",\n",
            "    \"name\": \"Sarah Johnson\",\n",
            "    \"email\": \"sarah.j@email.com\",\n",
            "    \"message\": \"Interested in math tutoring for daughter.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# View all collected leads\n",
        "print(\"\\nüìù LEADS DATABASE:\")\n",
        "print(json.dumps(leads_database, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ea4b247d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea4b247d",
        "outputId": "6349cfd5-87f7-4465-b203-4d67ff007246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üí¨ FEEDBACK DATABASE:\n",
            "[\n",
            "  {\n",
            "    \"timestamp\": \"2025-10-19 16:57:50\",\n",
            "    \"question\": \"What's TutorBee's refund policy?\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# View all collected feedback\n",
        "print(\"\\nüí¨ FEEDBACK DATABASE:\")\n",
        "print(json.dumps(feedback_database, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "45edc6e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "45edc6e7",
        "outputId": "b6b1723b-61a3-4e48-dc7f-4e55d55958ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85cb8ea4-80a7-4484-bc11-491dd1ef74f1\", \"leads_log.json\", 173)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Leads downloaded!\n"
          ]
        }
      ],
      "source": [
        "# Download leads as JSON file\n",
        "from google.colab import files\n",
        "\n",
        "if leads_database:\n",
        "    files.download('leads_log.json')\n",
        "    print(\"‚úÖ Leads downloaded!\")\n",
        "else:\n",
        "    print(\"No leads to download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f7efee39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f7efee39",
        "outputId": "cedd1bb1-543d-44aa-d07f-8f6ec05eea80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0c574fa7-5099-4633-bf6f-ca4e25a4af54\", \"feedback_log.json\", 102)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feedback downloaded!\n"
          ]
        }
      ],
      "source": [
        "# Download feedback as JSON file\n",
        "from google.colab import files\n",
        "\n",
        "if feedback_database:\n",
        "    files.download('feedback_log.json')\n",
        "    print(\"‚úÖ Feedback downloaded!\")\n",
        "else:\n",
        "    print(\"No feedback to download.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}